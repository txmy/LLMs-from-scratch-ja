# 第3章: アテンション機構をコーディングする

&nbsp;
## メインチャプターコード

- [01_main-chapter-code](01_main-chapter-code) メインチャプターコードを含む。

&nbsp;
## ボーナス教材

- [02_bonus_efficient-multihead-attention](02_bonus_efficient-multihead-attention) マルチヘッドアテンションの異なる実装バリアントを実装し比較する
- [03_understanding-buffers](03_understanding-buffers) 第3章で因果的アテンション機構を実装するために使用されるPyTorchバッファの考え方を説明する



以下のビデオでは、章の内容の一部を補足教材としてカバーするコードアロングセッションを提供しています。

<br>
<br>

[![Link to the video](https://img.youtube.com/vi/-Ll8DtpNtvk/0.jpg)](https://www.youtube.com/watch?v=-Ll8DtpNtvk)