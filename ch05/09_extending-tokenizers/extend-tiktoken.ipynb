{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbc1fe3-bff1-4631-bf35-342e19c54cc0",
   "metadata": {},
   "source": "<table style=\"width:100%\">\n<tr>\n<td style=\"vertical-align:middle; text-align:left;\">\n<font size=\"2\">\n<a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>（大規模言語モデルをスクラッチから構築）書籍の補足コード<br>\n著者：<a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n<br>コードリポジトリ：<a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n</font>\n</td>\n<td style=\"vertical-align:middle; text-align:left;\">\n<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n</td>\n</tr>\n</table>"
  },
  {
   "cell_type": "markdown",
   "id": "2b022374-e3f6-4437-b86f-e6f8f94cbebc",
   "metadata": {},
   "source": "# Tiktoken BPEトークナイザーへの新しいトークンの追加"
  },
  {
   "cell_type": "markdown",
   "id": "bcd624b1-2060-49af-bbf6-40517a58c128",
   "metadata": {},
   "source": "- このノートブックでは、既存のBPEトークナイザーを拡張する方法を説明します。特に、人気の高い[tiktoken](https://github.com/openai/tiktoken)実装での方法に焦点を当てます\n- トークン化の一般的な紹介については、[第2章](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/01_main-chapter-code/ch02.ipynb)およびBPE from Scratch [link]チュートリアルを参照してください\n- 例えば、GPT-2トークナイザーがあり、次のテキストをエンコードしたいとします："
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798d4355-a146-48a8-a1a5-c5cec91edf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 2011, 3791, 30642, 62, 16, 318, 257, 649, 11241, 13, 220, 50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "base_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "sample_text = \"Hello, MyNewToken_1 is a new token. <|endoftext|>\"\n",
    "\n",
    "token_ids = base_tokenizer.encode(sample_text, allowed_special={\"<|endoftext|>\"})\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b09b19b-772d-4449-971b-8ab052ee726d",
   "metadata": {},
   "source": "- 各トークンIDを繰り返し処理することで、語彙を介してトークンIDがどのようにデコードされるかをよりよく理解できます："
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fd634b-bb4c-4ba3-8b69-9322b727bf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15496 -> Hello\n",
      "11 -> ,\n",
      "2011 ->  My\n",
      "3791 -> New\n",
      "30642 -> Token\n",
      "62 -> _\n",
      "16 -> 1\n",
      "318 ->  is\n",
      "257 ->  a\n",
      "649 ->  new\n",
      "11241 ->  token\n",
      "13 -> .\n",
      "220 ->  \n",
      "50256 -> <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for token_id in token_ids:\n",
    "    print(f\"{token_id} -> {base_tokenizer.decode([token_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b1b9b-b1a9-489e-9711-c15a8e081813",
   "metadata": {},
   "source": "- 上記のように、`\"MyNewToken_1\"`は5つの個別のサブワードトークンに分解されています -- これは未知の単語を扱うBPEの通常の動作です\n- しかし、他の単語や`\"<|endoftext|>\"`と同様に、単一のトークンとしてエンコードしたい特殊トークンである場合を想定してください。このノートブックではその方法を説明します"
  },
  {
   "cell_type": "markdown",
   "id": "65f62ab6-df96-4f88-ab9a-37702cd30f5f",
   "metadata": {},
   "source": "&nbsp;\n## 1. 特殊トークンの追加"
  },
  {
   "cell_type": "markdown",
   "id": "c4379fdb-57ba-4a75-9183-0aee0836c391",
   "metadata": {},
   "source": "- 新しいトークンは特殊トークンとして追加する必要があることに注意してください。理由は、トークナイザーの訓練プロセス中に作成される新しいトークンの「マージ」がないためです -- たとえそれらを持っていたとしても、既存のトークン化スキームを壊さずにそれらを組み込むことは非常に困難です（「マージ」を理解するには、BPE from scratchノートブック [link]を参照してください）\n- 2つの新しいトークンを追加したいとします："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f1bba-c478-497d-b7fc-f4bd191b7d55",
   "metadata": {},
   "outputs": [],
   "source": "# カスタムトークンとそのトークンIDを定義\ncustom_tokens = [\"MyNewToken_1\", \"MyNewToken_2\"]\ncustom_token_ids = {\n    token: base_tokenizer.n_vocab + i for i, token in enumerate(custom_tokens)\n}"
  },
  {
   "cell_type": "markdown",
   "id": "1c6f3d98-1ab6-43cf-9ae2-2bf53860f99e",
   "metadata": {},
   "source": "- 次に、特殊トークンを保持するカスタム`Encoding`オブジェクトを次のように作成します："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f519852-59ea-4069-a8c7-0f647bfaea09",
   "metadata": {},
   "outputs": [],
   "source": "# 拡張トークンを含む新しいEncodingオブジェクトを作成\nextended_tokenizer = tiktoken.Encoding(\n    name=\"gpt2_custom\",\n    pat_str=base_tokenizer._pat_str,\n    mergeable_ranks=base_tokenizer._mergeable_ranks,\n    special_tokens={**base_tokenizer._special_tokens, **custom_token_ids},\n)"
  },
  {
   "cell_type": "markdown",
   "id": "90af6cfa-e0cc-4c80-89dc-3a824e7bdeb2",
   "metadata": {},
   "source": "- 以上で、サンプルテキストをエンコードできることを確認できます："
  },
  {
   "cell_type": "markdown",
   "id": "153e8e1d-c4cb-41ff-9c55-1701e9bcae1c",
   "metadata": {},
   "source": "- ご覧のとおり、新しいトークン`50257`と`50258`が出力にエンコードされています："
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccc78a4-1fd4-47ba-a114-83ee0a3aec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36674, 2420, 351, 220, 50257, 290, 220, 50258, 13, 220, 50256]\n"
     ]
    }
   ],
   "source": [
    "special_tokens_set = set(custom_tokens) | {\"<|endoftext|>\"}\n",
    "\n",
    "token_ids = extended_tokenizer.encode(\n",
    "    \"Sample text with MyNewToken_1 and MyNewToken_2. <|endoftext|>\",\n",
    "    allowed_special=special_tokens_set\n",
    ")\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0547c1-bbb5-4915-8cf4-caaebcf922eb",
   "metadata": {},
   "source": "- 繰り返しになりますが、トークンごとに見ることもできます："
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7583eff9-b10d-4e3d-802c-f0464e1ef030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36674 -> Sample\n",
      "2420 ->  text\n",
      "351 ->  with\n",
      "220 ->  \n",
      "50257 -> MyNewToken_1\n",
      "290 ->  and\n",
      "220 ->  \n",
      "50258 -> MyNewToken_2\n",
      "13 -> .\n",
      "220 ->  \n",
      "50256 -> <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "for token_id in token_ids:\n",
    "    print(f\"{token_id} -> {extended_tokenizer.decode([token_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0764e-e5a9-4226-a384-18c11bd5fec3",
   "metadata": {},
   "source": "- 上記のとおり、トークナイザーの更新に成功しました\n- ただし、事前訓練済みLLMで使用するには、LLMの埋め込み層と出力層も更新する必要があります。これについては次のセクションで説明します"
  },
  {
   "cell_type": "markdown",
   "id": "8ec7f98d-8f09-4386-83f0-9bec68ef7f66",
   "metadata": {},
   "source": "&nbsp;\n## 2. 事前訓練済みLLMの更新"
  },
  {
   "cell_type": "markdown",
   "id": "b8a4f68b-04e9-4524-8df4-8718c7b566f2",
   "metadata": {},
   "source": "- このセクションでは、トークナイザーを更新した後、既存の事前訓練済みLLMを更新する方法を見ていきます\n- このために、メインブックで使用されているオリジナルの事前訓練済みGPT-2モデルを使用します"
  },
  {
   "cell_type": "markdown",
   "id": "1a9b252e-1d1d-4ddf-b9f3-95bd6ba505a9",
   "metadata": {},
   "source": "&nbsp;\n### 2.1 事前訓練済みGPTモデルのロード"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded29b4e-9b39-4191-b61c-29d6b2360bae",
   "metadata": {},
   "outputs": [],
   "source": "from llms_from_scratch.ch05 import download_and_load_gpt2\n# llms_from_scratchのインストール手順については、以下を参照してください：\n# https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n\nsettings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc0d8e-b549-415b-840e-a00023bddcf9",
   "metadata": {},
   "outputs": [],
   "source": "from llms_from_scratch.ch04 import GPTModel\n# llms_from_scratchのインストール手順については、以下を参照してください：\n# https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n\nGPT_CONFIG_124M = {\n    \"vocab_size\": 50257,   # 語彙サイズ\n    \"context_length\": 256, # 短縮されたコンテキスト長（元：1024）\n    \"emb_dim\": 768,        # 埋め込み次元\n    \"n_heads\": 12,         # アテンションヘッド数\n    \"n_layers\": 12,        # レイヤー数\n    \"drop_rate\": 0.1,      # ドロップアウト率\n    \"qkv_bias\": False      # クエリ・キー・バリューバイアス\n}\n\n# コンパクトさのためにモデル設定を辞書で定義\nmodel_configs = {\n    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n}\n\n# ベース設定をコピーして特定のモデル設定で更新\nmodel_name = \"gpt2-small (124M)\"  # モデル名の例\nNEW_CONFIG = GPT_CONFIG_124M.copy()\nNEW_CONFIG.update(model_configs[model_name])\nNEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n\ngpt = GPTModel(NEW_CONFIG)\ngpt.eval();"
  },
  {
   "cell_type": "markdown",
   "id": "83f898c0-18f4-49ce-9b1f-3203a277b29e",
   "metadata": {},
   "source": "### 2.2 事前訓練済みGPTモデルの使用"
  },
  {
   "cell_type": "markdown",
   "id": "a5a1f5e1-e806-4c60-abaa-42ae8564908c",
   "metadata": {},
   "source": "- 次に、オリジナルと新しいトークナイザーを使ってトークン化する以下のサンプルテキストを検討します："
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a88017d-cc8f-4ba1-bba9-38161a30f673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_text = \"Sample text with MyNewToken_1 and MyNewToken_2. <|endoftext|>\"\n",
    "\n",
    "original_token_ids = base_tokenizer.encode(\n",
    "    sample_text, allowed_special={\"<|endoftext|>\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee01bc3-ca24-497b-b540-3d13c52c29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token_ids = extended_tokenizer.encode(\n",
    "    \"Sample text with MyNewToken_1 and MyNewToken_2. <|endoftext|>\",\n",
    "    allowed_special=special_tokens_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1143106b-68fe-4234-98ad-eaff420a4d08",
   "metadata": {},
   "source": "- では、オリジナルのトークンIDをGPTモデルに与えてみましょう："
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b06827f-b411-42cc-b978-5c1d568a3200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2204,  0.8901,  1.0138,  ...,  0.2585, -0.9192, -0.2298],\n",
      "         [ 0.6745, -0.0726,  0.8218,  ..., -0.1768, -0.4217,  0.0703],\n",
      "         [-0.2009,  0.0814,  0.2417,  ...,  0.3166,  0.3629,  1.3400],\n",
      "         ...,\n",
      "         [ 0.1137, -0.1258,  2.0193,  ..., -0.0314, -0.4288, -0.1487],\n",
      "         [-1.1983, -0.2050, -0.1337,  ..., -0.0849, -0.4863, -0.1076],\n",
      "         [-1.0675, -0.5905,  0.2873,  ..., -0.0979, -0.8713,  0.8415]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = gpt(torch.tensor([original_token_ids]))\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c7a78-35a8-473e-a08d-b099a6348a74",
   "metadata": {},
   "source": "- 上記のように、これは問題なく動作します（注：コードはシンプルにするため、出力をテキストに変換せずに生の出力を示しています。詳細については、第5章 [link] セクション5.3.3の`generate`関数を確認してください）"
  },
  {
   "cell_type": "markdown",
   "id": "628265b5-3dde-44e7-bde2-8fc594a2547d",
   "metadata": {},
   "source": "- 更新されたトークナイザーで生成されたトークンIDで同じことを試すとどうなるでしょうか？"
  },
  {
   "cell_type": "markdown",
   "id": "9796ad09-787c-4c25-a7f5-6d1dfe048ac3",
   "metadata": {},
   "source": "```python\nwith torch.no_grad():\n    gpt(torch.tensor([new_token_ids]))\n\nprint(out)\n\n...\n# IndexError: インデックスが範囲外です\n```"
  },
  {
   "cell_type": "markdown",
   "id": "77d00244-7e40-4de0-942e-e15cdd8e3b18",
   "metadata": {},
   "source": "- ご覧のとおり、これはインデックスエラーになります\n- その理由は、GPTモデルが入力埋め込み層と出力層を介して固定語彙サイズを期待しているためです：\n\n<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/extend-tiktoken/gpt-updates.webp\" width=\"400px\">"
  },
  {
   "cell_type": "markdown",
   "id": "dec38b24-c845-4090-96a4-0d3c4ec241d6",
   "metadata": {},
   "source": "&nbsp;\n### 2.3 埋め込み層の更新"
  },
  {
   "cell_type": "markdown",
   "id": "b1328726-8297-4162-878b-a5daff7de742",
   "metadata": {},
   "source": "- 埋め込み層の更新から始めましょう\n- まず、埋め込み層には語彙サイズに対応する50,257個のエントリがあることに注意してください："
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ecab6e-1232-47c7-a318-042f90e1dff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.tok_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d760c683-d082-470a-bff8-5a08b30d3b61",
   "metadata": {},
   "source": "- この埋め込み層に2つのエントリを追加して拡張したいと思います\n- 簡単に言えば、より大きなサイズの新しい埋め込み層を作成し、古い埋め込み層の値をコピーします"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5c48e-c6fe-4e84-b290-04bd4da9483f",
   "metadata": {},
   "outputs": [],
   "source": "num_tokens, emb_size = gpt.tok_emb.weight.shape\nnew_num_tokens = num_tokens + 2\n\n# 新しい埋め込み層を作成\nnew_embedding = torch.nn.Embedding(new_num_tokens, emb_size)\n\n# 古い埋め込み層から重みをコピー\nnew_embedding.weight.data[:num_tokens] = gpt.tok_emb.weight.data\n\n# モデル内の古い埋め込み層を新しいものに置き換え\ngpt.tok_emb = new_embedding\n\nprint(gpt.tok_emb)"
  },
  {
   "cell_type": "markdown",
   "id": "63954928-31a5-4e7e-9688-2e0c156b7302",
   "metadata": {},
   "source": "- 上記のとおり、埋め込み層が増加しました"
  },
  {
   "cell_type": "markdown",
   "id": "6e68bea5-255b-47bb-b352-09ea9539bc25",
   "metadata": {},
   "source": "&nbsp;\n### 2.4 出力層の更新"
  },
  {
   "cell_type": "markdown",
   "id": "90a4a519-bf0f-4502-912d-ef0ac7a9deab",
   "metadata": {},
   "source": "- 次に、埋め込み層と同様に語彙サイズに対応する50,257の出力特徴を持つ出力層を拡張する必要があります（ちなみに、PyTorchのLinearとEmbedding層の類似性について議論しているボーナス資料も役立つかもしれません）"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6105922f-d889-423e-bbcc-bc49156d78df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.out_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1ff24-9c00-40f6-a94f-82d03aaf0890",
   "metadata": {},
   "source": "- 出力層の拡張手順は、埋め込み層の拡張と同様です："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354589db-b148-4dae-8068-62132e3fb38e",
   "metadata": {},
   "outputs": [],
   "source": "original_out_features, original_in_features = gpt.out_head.weight.shape\n\n# 新しい出力特徴数を定義（例：2つの新しいトークンを追加）\nnew_out_features = original_out_features + 2\n\n# 拡張された出力サイズで新しい線形層を作成\nnew_linear = torch.nn.Linear(original_in_features, new_out_features)\n\n# 元の線形層から重みとバイアスをコピー\nwith torch.no_grad():\n    new_linear.weight[:original_out_features] = gpt.out_head.weight\n    if gpt.out_head.bias is not None:\n        new_linear.bias[:original_out_features] = gpt.out_head.bias\n\n# 元の線形層を新しいものに置き換え\ngpt.out_head = new_linear\n\nprint(gpt.out_head)"
  },
  {
   "cell_type": "markdown",
   "id": "df5d2205-1fae-4a4f-a7bd-fa8fc37eeec2",
   "metadata": {},
   "source": "- まず、この更新されたモデルをオリジナルのトークンIDで試してみましょう："
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df604bbc-6c13-4792-8ba8-ecb692117c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2267,  0.9132,  1.0494,  ..., -0.2330, -0.3008, -1.1458],\n",
      "         [ 0.6808, -0.0495,  0.8574,  ...,  0.0671,  0.5572, -0.7873],\n",
      "         [-0.1947,  0.1045,  0.2773,  ...,  1.3368,  0.8479, -0.9660],\n",
      "         ...,\n",
      "         [ 0.1200, -0.1027,  2.0549,  ..., -0.1519, -0.2096,  0.5651],\n",
      "         [-1.1920, -0.1819, -0.0981,  ..., -0.1108,  0.8435, -0.3771],\n",
      "         [-1.0612, -0.5674,  0.3229,  ...,  0.8383, -0.7121, -0.4850]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = gpt(torch.tensor([original_token_ids]))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80717e-50e6-4927-8129-0aadfa2628f5",
   "metadata": {},
   "source": "- 次に、更新されたトークンで試してみましょう："
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75f11ec9-bdd2-440f-b8c8-6646b75891c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2267,  0.9132,  1.0494,  ..., -0.2330, -0.3008, -1.1458],\n",
      "         [ 0.6808, -0.0495,  0.8574,  ...,  0.0671,  0.5572, -0.7873],\n",
      "         [-0.1947,  0.1045,  0.2773,  ...,  1.3368,  0.8479, -0.9660],\n",
      "         ...,\n",
      "         [-0.0656, -1.2451,  0.7957,  ..., -1.2124,  0.1044,  0.5088],\n",
      "         [-1.1561, -0.7380, -0.0645,  ..., -0.4373,  1.1401, -0.3903],\n",
      "         [-0.8961, -0.6437, -0.1667,  ...,  0.5663, -0.5862, -0.4020]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = gpt(torch.tensor([new_token_ids]))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a1bba-db01-4090-97e4-25dfc23ed54c",
   "metadata": {},
   "source": "- ご覧のとおり、モデルは拡張されたトークンセットで動作します\n- 実際には、新しいトークンを含むデータでモデル（特に新しい埋め込み層と出力層）をファインチューニング（または継続的に事前訓練）したいと思うでしょう"
  },
  {
   "cell_type": "markdown",
   "id": "6de573ad-0338-40d9-9dad-de60ae349c4f",
   "metadata": {},
   "source": "**重み共有についての注記**\n\n- モデルが重み共有を使用している場合、つまり埋め込み層と出力層が同じ重みを共有している場合（Llama 3 [link]と同様）、出力層の更新ははるかに簡単です\n- この場合、単に埋め込み層から重みをコピーできます："
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cbc5f51-c7a8-49d0-b87f-d3d87510953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.out_head.weight = gpt.tok_emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0d553a8-edff-40f0-bdc4-dff900e16caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = gpt(torch.tensor([new_token_ids]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}